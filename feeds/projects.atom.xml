<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jeffrey Luppes - Projects</title><link href="www.jeffluppes.nl/" rel="alternate"></link><link href="www.jeffluppes.nl/feeds/projects.atom.xml" rel="self"></link><id>www.jeffluppes.nl/</id><updated>2020-03-25T12:03:38+01:00</updated><subtitle>Machine Learning Engineer and Data Scientist</subtitle><entry><title>The class of 2015 - An analysis in what jobs the people I graduated with ended up</title><link href="www.jeffluppes.nl/the-class-of-2015-an-analysis-in-what-jobs-the-people-i-graduated-with-ended-up.html" rel="alternate"></link><published>2020-03-25T12:03:38+01:00</published><updated>2020-03-25T12:03:38+01:00</updated><author><name>Jeffrey Luppes</name></author><id>tag:None,2020-03-25:www.jeffluppes.nl/the-class-of-2015-an-analysis-in-what-jobs-the-people-i-graduated-with-ended-up.html</id><summary type="html">&lt;p&gt;Computer Science degrees are notorious for their attrition rate and a lot of people switch degrees. I've switched twice myself, going from CS to AI and then to Software Engineering. Due to the way the Dutch system is organized this almost meant starting from scratch. Frankly, not my best decisions …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Computer Science degrees are notorious for their attrition rate and a lot of people switch degrees. I've switched twice myself, going from CS to AI and then to Software Engineering. Due to the way the Dutch system is organized this almost meant starting from scratch. Frankly, not my best decisions. But I was young.&lt;/p&gt;
&lt;p&gt;I figured that it could be interesting to look what everyone was doing now. Most people generally do find their way to the finish line and there is also a substantial part that starts working and doesnt finish their degree. Interestingly, the Hanze University of Applied Science &lt;a href="https://www.itacademy.nl/kennisbank/factsheets/factsheet"&gt;had the same idea&lt;/a&gt; and scraped linkedIn profiles of all their alumni - assumingly me included. They found that the top 3 roles for software engineers were:&lt;/p&gt;
&lt;!-- more --&gt;
&lt;ul&gt;
&lt;li&gt;Developer&lt;/li&gt;
&lt;li&gt;Software Engineer&lt;/li&gt;
&lt;li&gt;Consultant&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I decided to do the same, but the motivation for me is a little different than the Hanze. For GDPR reasons the Hanze can claim their possession of this data is justified: after all, they should know where their graduates end up so they can adjust their curriculum every few decades. I also did not need to redo their work and classify the size of the company someone worked at or the location (North or Randstad et cetera..)&lt;/p&gt;
&lt;h2&gt;Wait, where's that attendance list?&lt;/h2&gt;
&lt;p&gt;I still had a grades list from the end of year 1 at which point there were 100 students left. Having made it through the first year, most would go on and graduate. Since scraping is a bit out of the question here, I decided to hit up their linkedin myself (and often saying hi or sending a friend request). I'd only collect their job title from Linkedin, which I added to a CSV.&lt;/p&gt;
&lt;p&gt;Sure enough, out of &lt;strong&gt;103&lt;/strong&gt; students, there were &lt;strong&gt;78&lt;/strong&gt; I could find on LinkedIn. I saw happy faces and a lot of heavy metal shirts. Some people had left IT altogether. Some were doing a master's degree. Some had started a company abroad. It seems that the people I could not find had might've done so to minimize their footprint online, especially not uncommon when one goes into security.&lt;/p&gt;
&lt;p&gt;At this point I did some limited post-processing on this list. I removed terms such as medior or senior (side note: hardly anyone was a junior) and tried to merge the various security, consultancy, and dev-related roles together towards a standardized format. Application Developer became Software Developer, but .NET developers and embedded systems developers kept their title. This is a bit arbitrary and opens up this little adventure to bias.&lt;/p&gt;
&lt;p&gt;I removed eight non-IT roles, such as caretaker, military, nurse and store manager. For double roles I tried figuring out which was more reasonable. For instance if someone had founded a succesful company but still listed themselves as an developer, I figured that the Founder role was more defining.&lt;/p&gt;
&lt;h2&gt;Findings&lt;/h2&gt;
&lt;p&gt;Little to no surprise was that the top three is pretty much the same still the same. The full list is below, but here are some things that stood out to me:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Only two people started a company&lt;/li&gt;
&lt;li&gt;There are no data scientists&lt;/li&gt;
&lt;li&gt;Likewise, there are no software engineers in BI roles.&lt;/li&gt;
&lt;li&gt;Two people are currently doing an internship - most likely as a part of a MSc degree requirement.&lt;/li&gt;
&lt;li&gt;There is exactly one Software Architect&lt;/li&gt;
&lt;li&gt;In the same vein of requiring experience, there are a handful of managers, but mostly related to products and not teams.&lt;/li&gt;
&lt;li&gt;There are several cloud engineers. Back in 2015, this role was pretty much unheard of.&lt;/li&gt;
&lt;li&gt;Yours truly is the only Machine Learning Engineer to make the sample.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My curiousity is now satisfied, but not before I made a word cloud of this collection.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Word cloud" src="/images/students.png"&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Job title&lt;/th&gt;
&lt;th&gt;Count (n=70)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Software Developer&lt;/td&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Software Engineer&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Consultant&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;.NET Developer&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cloud Engineer&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Full-stack Developer&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Project Manager&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Product Owner&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Founder&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Security Consultant&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Network Engineer&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Intern&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Back-end Developer&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Account Manager&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Service Manager&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Solution Developer&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Embedded Software Engineer&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Functional Application Manager&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mobile Developer&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Systems Engineer&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Front-end Developer&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Machine Learning Engineer&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Scrum Master&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Web Developer&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Field Engineer&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Change Manager&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Solution Experience Manager&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Software Architect&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DBA&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Sysadmin&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img alt="Roles" src="/images/student_roles.png"&gt;&lt;/p&gt;</content><category term="Projects"></category><category term="Linkedin"></category><category term="Programming"></category><category term="Web Scraping"></category><category term="Python"></category></entry><entry><title>Building a bird detector from scratch with web scraping and deep learning (part 1)</title><link href="www.jeffluppes.nl/building-a-bird-detector-from-scratch-with-web-scraping-and-deep-learning-part-1.html" rel="alternate"></link><published>2020-01-21T19:46:47+01:00</published><updated>2020-01-21T19:46:47+01:00</updated><author><name>Jeffrey Luppes</name></author><id>tag:None,2020-01-21:www.jeffluppes.nl/building-a-bird-detector-from-scratch-with-web-scraping-and-deep-learning-part-1.html</id><summary type="html">&lt;p&gt;&lt;img alt="Birbs. Image by author." src="/images/vogels0.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This is part 1 in a series on this project, more posts will be written as the project progresses&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I'm an awful birder. While I've always been interested in birds I'm almost completely deaf to identifying them by their calls. I never started memorizing them and my ability to recognize …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="Birbs. Image by author." src="/images/vogels0.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This is part 1 in a series on this project, more posts will be written as the project progresses&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I'm an awful birder. While I've always been interested in birds I'm almost completely deaf to identifying them by their calls. I never started memorizing them and my ability to recognize them on the basis of visual cues is poor. It was only when I started kayaking (about five years ago) that I was exposed to more bird-watching, and during a trip to Schotland last year a couple of friends took me on my first bird watching trip. &lt;/p&gt;
&lt;p&gt;So given that my human-based detection is obviously lacking I figured that with the plethora of bird data online, would it perhaps not be possible to scrape these and create a bird classifier using CNNs and general Python shenanigans? &lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2&gt;Intro&lt;/h2&gt;
&lt;p&gt;I also wanted to make a funny trinket out of this and deploy it to a Pi. I'm lucky to have family that live on a farm in a rural area and have multiple feeding stations for the birds. Apart from the 30-or so bird species that they've actively tracked over the past year, there are also chickens, hedgehogs, mice, rats, and various predators like hawks and foxes that drop by. Some of the feeding stations are viewable from indoors, while others are between trees and bush. This will be the testing ground.  &lt;/p&gt;
&lt;p&gt;This is actually a very active research topic in the past couple of years, as ecologists, population biologists and researchers are using deep learning to automate detection. Consider that according to a May 2018 paper, roughly one third of papers on this subject was published in 2017 and 2018 [1]. Focus is particular on video and audio (e.g. bird calls).&lt;/p&gt;
&lt;p&gt;As for approaches, it seems that my idea of CNNs and Pis is spot on. [2] Shows a CNN model with skip connections traind on 27 bird species in Taiwan can approach 99% accuracy. There is also another source that shows it is possible to use a Raspberry Pi for classification amongst three species [3]. And that's just scraping the surface: more advanced models are being developed. Further inspiration comes from Ben Hamm and his cat Metric [4]:&lt;/p&gt;
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/1A-Nf3QIJjM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;One particular website that's a huge hub for biologists and bird-watchers is the Dutch site www.waarneming.nl. It's worth mentioning waarneming employs their own suite of models and automatically classifies uploaded photos. In 2019, they received around eight million photos. With this data they've also put out their own deep learning-powered app: &lt;a href="https://play.google.com/store/apps/details?id=org.observation.obsidentify&amp;amp;hl=en"&gt;Obsidentify&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;But why would anyone do this if there's already apps (and with that probably APIs) that do this? For starters, I like the idea and challenge of bringing this end to end. It's a learning experience for me. Secondly, I like to gift this set up to my in-laws at some point so to have some kind of automated tracking when there's something going on in the garden. Scientifically this is a valid topic: bird classification scales poorly as does droning over photos or video streams is a labour-intensive task. &lt;/p&gt;
&lt;h2&gt;Why is this a hard problem?&lt;/h2&gt;
&lt;p&gt;While the training data mostly contains photo's of birds zoomed up and resting on a branch, the real-life data is much more messier. Consider this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Birds do, in general, not sit still long enough&lt;/li&gt;
&lt;li&gt;There might be multiple birds and multiple species in a single shot&lt;/li&gt;
&lt;li&gt;The size of a birds vary &lt;/li&gt;
&lt;li&gt;Many bird species are dimorphic: males and females look different&lt;/li&gt;
&lt;li&gt;Every bird species has different feeding strategies which result in different images, with some more inclined to frequent a station than others.&lt;/li&gt;
&lt;li&gt;They might be in an odd point of view (e.g. viewing a bird from the rear)&lt;/li&gt;
&lt;li&gt;Training data of the same species from different areas might be too different&lt;/li&gt;
&lt;li&gt;The background (branches, fields) is very different from the feeding stations. Consider the "wolf vs background" problem where an AI system trained to distinguish wolves was actually picking up on the presence of snow in the training image to determine whether the photo was of a wolf or dog instead of the actual subject. This is a valid problem in this context&lt;/li&gt;
&lt;li&gt;There might be a number of branches and foilage in the way of the birds (consider, for instance the header image of this post)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;As for actually doing it:&lt;/strong&gt;
- Training a neural network simply requires a ton of labelled data.
- There is a huge difference between photos shot with a telescopic lens of say 250mm+ and a wide-angle over the counter camera such as a the pi camera
- The quality of these webcams, action cams and the pi-camera might simply be too bad to do this
- Some excellent training data might explictely forbid usage (licence)
- Some of the images available are simply cell-phone camera shots through a telescope or of a DSLR-display.
- In order to adequately classify birds, I have to recognize (a) an image contains a bird (a binary problem), (b) find where in the image the bird is and predict a bounding box around it and (c) classify the bird.&lt;/p&gt;
&lt;p&gt;In all, there's a large potential for a miss-match between the training data and the real-world case I'm trying to work on. &lt;/p&gt;
&lt;h2&gt;Act 1: Identifying training data&lt;/h2&gt;
&lt;p&gt;&lt;a href="www.waarneming.nl"&gt;Waarneming.nl&lt;/a&gt; has photo's publicly available and the data is relatively easy to access. Since the goal environment (a farm in the Netherlands) and the training data environment (most uploads are from Belgium and the Netherlands) are the same, this was my first choice for training data.&lt;/p&gt;
&lt;p&gt;There's also &lt;a href="https://www.flickr.com/services/api/"&gt;Flickr&lt;/a&gt; which even publicly exposes an API for these goals. This might be the best / easiest option if you're not looking for data from Europe. &lt;a href="https://ebird.org/home"&gt;eBird&lt;/a&gt; seems to be scrape-able the same way. While searching for 'Staartmees' on Flickr yields only about 2000 hits, checking for 'Long-tailed tit' gives around 62.000 photos. &lt;/p&gt;
&lt;p&gt;Lastly, there are two datasets that might be of use. First there's the &lt;a href="http://www.vision.caltech.edu/visipedia/CUB-200-2011.html"&gt;Caltech-UCSD Birds-200-2011
&lt;/a&gt; data set of almost 12000 photos and 200 species. This information may be useful later on for detecting a bounding box (a square to identify &lt;em&gt;where&lt;/em&gt; in an image a bird is located) around a bird. Similarly, there is the &lt;a href="http://bird.nae-lab.org/dataset/"&gt;Japanese Wild Birds in a Wind Farm: Image Dataset for Bird Detection&lt;/a&gt; data set for detection, although this is again only useful for detection and not classification - an important distinction.&lt;/p&gt;
&lt;h2&gt;Act 2: Scraping training data&lt;/h2&gt;
&lt;p&gt;I set out to scrape the data from waarneming.nl as this is the absolute closest to my real-life use case and the image quality is insanely high, being mostly from birders with professional gear. Futhermore, as the data is community-sourced and often verified, I can directly treat the image labels as based in truth (something that would not be possible with say Flickr). I turned to the gallery:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Waarneming Gallery" src="/images/vogels1.png"&gt;&lt;/p&gt;
&lt;p&gt;Waarneming has a gallery function that lists 24 bird photos each time. Despite there being more images on the site than the gallery, only the gallery has the &lt;code&gt;app-ratio-box-image&lt;/code&gt; class, so this allows us to collect only these links. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Html of the gallery" src="/images/vogels2.png"&gt;&lt;/p&gt;
&lt;p&gt;Also note that the html includes links to the image (ending in &lt;code&gt;.jpg&lt;/code&gt;) as a page describing an image (ending with &lt;code&gt;photos/&amp;lt;image_id&amp;gt;/&lt;/code&gt;. This leads to a page that has meta data on the image - more on that in a bit.&lt;/p&gt;
&lt;p&gt;Based on the species list (below) I looked at querying for each specific bird. However, there are many possible species and a simple search might return multiple possible hits (subspecies might be returned). Since I'd have to make a list of each species' latin name anyway, I just searched for an individual species and collected the species' id. I stored these in a dict like below:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;species_name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;species_x&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;id&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;For each species in the list I crawled the site. I could not find a robots.txt that disallowed web scraping and the license found on &lt;a href="https://waarneming.nl/tos/"&gt;https://waarneming.nl/tos/&lt;/a&gt; explictely permits non-commercial use by individuls. However, because the strain on a website can be considerable it is a good practise to build in a pause of 1 second between requests. I did not initially do this as I had honestly had not considered the strain on their servers. &lt;/p&gt;
&lt;p&gt;The below script accomplishes the main scraping goals. I made use of the &lt;code&gt;beautifulsoup&lt;/code&gt; and &lt;code&gt;requests&lt;/code&gt; libraries to collect the html from the pages and parse them. I also included a call to check which images I already have downloaded, so I don't waste resources fetching the same image twice. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MAXIMAGES&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;IMAGESPERPAGE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# construct the url&lt;/span&gt;
    &lt;span class="n"&gt;URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;https://waarneming.nl/species/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;identifier&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/photos/&amp;#39;&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;?after_date=2018-01-01&amp;amp;before_date=2020-01-19&amp;amp;page=&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# fetch the url and content&lt;/span&gt;
    &lt;span class="n"&gt;page&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;URL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;html.parser&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;#find the images&lt;/span&gt;
    &lt;span class="n"&gt;tags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;findAll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;img&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;class&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;app-ratio-box-image&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
    &lt;span class="n"&gt;photolinks&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;tags&lt;/span&gt;

    &lt;span class="c1"&gt;#pause for one second out of courtesy&lt;/span&gt;
    &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# get the photoids we already have scraped from before&lt;/span&gt;
&lt;span class="n"&gt;photoids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_photoid_list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;species&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;metadata&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="c1"&gt;# download photos and store them in their new home&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;link&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;photolinks&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;#url without arguments&lt;/span&gt;
    &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;src&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;?w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="c1"&gt;#obtain filename from url&lt;/span&gt;
    &lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="c1"&gt;#check if we have encountered this photo before - will be substantially slower with large n&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;photoids&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; 

        &lt;span class="c1"&gt;# we have a new photo, so lets check the metadata first&lt;/span&gt;
        &lt;span class="n"&gt;meta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_metadata&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;meta&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;meta&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;photoid&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;
            &lt;span class="n"&gt;metadata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;meta&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;meta&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Licentie&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;ALLOWED_LICENSES&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RAWFOLDER&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;species&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;
                &lt;span class="n"&gt;get_and_store_image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

                &lt;span class="c1"&gt;#also resize the image and store them seperately&lt;/span&gt;
                &lt;span class="n"&gt;outputpath&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PROCESSEDFOLDER&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;species&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.png&amp;#39;&lt;/span&gt;

                &lt;span class="n"&gt;convert_and_store_img&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;outputpath&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;new_photos&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

                &lt;span class="c1"&gt;#pause for one second out of courtesy&lt;/span&gt;
                &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The above code includes calls to the following methods and variables:
&lt;code&gt;get_photoid_list&lt;/code&gt; searches the &lt;code&gt;species&lt;/code&gt; directory for any existing photos (because there's no point in downloading the same photo twice if we re-run the script)
&lt;code&gt;ALLOWED_LICENSES&lt;/code&gt; contains a list of licences that allow us to scrape. 
&lt;code&gt;get_and_store_image&lt;/code&gt; requests the image from an url and stores it to local disk
&lt;code&gt;get_metadata&lt;/code&gt; requests the page that holds info on a particular &lt;code&gt;photoid&lt;/code&gt; and outputs the photo details to a &lt;code&gt;meta&lt;/code&gt; object. This way, we can trace which photo's we crawl and who made them, but also the license for an individual photo. 
&lt;code&gt;convert_and_store_img&lt;/code&gt; changes the photo to a set &lt;code&gt;x&lt;/code&gt; by &lt;code&gt;y&lt;/code&gt; size and also appends each image so all the training data has the same dimensions. 
&lt;code&gt;time.sleep(1)&lt;/code&gt; tells the scrape script to pause for one second.
&lt;code&gt;metadata&lt;/code&gt; is a list of &lt;code&gt;meta&lt;/code&gt; objects I store to disk afterwards.&lt;/p&gt;
&lt;p&gt;The attentive reader might notice we're also collecting metadata on images we don't scrape. This is mainly because I want to trace the different licences and other metadata associated with them and to verify that everything works correctly. The metadata is stored to a flat file. Below is the &lt;code&gt;get_metadata&lt;/code&gt; call:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_metadata&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;photoid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;24691898&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;Given a photo-id, return metadata in a dict&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

    &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;https://waarneming.nl/photos/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;photoid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;page&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;html.parser&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;tags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;table&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;class&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;table app-content-section&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
    &lt;span class="n"&gt;meta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="p"&gt;{}&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;tags&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="c1"&gt;# find all table rows&lt;/span&gt;
        &lt;span class="n"&gt;rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tags&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;tr&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;values&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="n"&gt;keys&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="c1"&gt;# get the table content and return as two lists&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="c1"&gt;# actual content is listed in the &amp;lt;td&amp;gt;, while &amp;lt;th&amp;gt; holds the keys. &lt;/span&gt;
            &lt;span class="n"&gt;descriptions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;th&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;cols&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;td&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ele&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;descriptions&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ele&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
                &lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cols&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;

        &lt;span class="c1"&gt;#create a dict out of the data we fetched&lt;/span&gt;
        &lt;span class="n"&gt;meta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;meta&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;...which returns the following:
&lt;img alt="Metadata" src="/images/vogels3.png"&gt;&lt;/p&gt;
&lt;p&gt;The data is contained in a table, and each row only contains a &lt;code&gt;&amp;lt;th&amp;gt;&lt;/code&gt; (header) and &lt;code&gt;&amp;lt;tr&amp;gt;&lt;/code&gt; (row). Thus, we obtain the keys from the &lt;code&gt;&amp;lt;th&amp;gt;&lt;/code&gt; and the values from information enclosed by the &lt;code&gt;&amp;lt;tr&amp;gt;&lt;/code&gt; tags. Note that we fail elegantly: if there's nothing in the table (or the table is not there) we return an empty meta. And if we do not have the meta object explictely stating what kind of value we have for a license, we don't download the photo. &lt;/p&gt;
&lt;p&gt;With that, we're all set to start scraping. Let's define what birds we want to look for. &lt;/p&gt;
&lt;h3&gt;Species list&lt;/h3&gt;
&lt;p&gt;The below lists the species I collected data about.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;#&lt;/th&gt;
&lt;th&gt;Latin NamE&lt;/th&gt;
&lt;th&gt;English Name&lt;/th&gt;
&lt;th&gt;Dutch Name&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Cyanistes caeruleus&lt;/td&gt;
&lt;td&gt;Eurasian blue tit&lt;/td&gt;
&lt;td&gt;Pimpelmees&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;Parus major&lt;/td&gt;
&lt;td&gt;Great tit&lt;/td&gt;
&lt;td&gt;Koolmees&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;Aegithalos caudatus&lt;/td&gt;
&lt;td&gt;Long-tailed tit&lt;/td&gt;
&lt;td&gt;Staartmees&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;Lophophanes cristatus&lt;/td&gt;
&lt;td&gt;European crested tit&lt;/td&gt;
&lt;td&gt;Kuifmees&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;Fringilla coelebs&lt;/td&gt;
&lt;td&gt;Common chaffinch&lt;/td&gt;
&lt;td&gt;Vink&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;Turdus merula&lt;/td&gt;
&lt;td&gt;Common blackbird&lt;/td&gt;
&lt;td&gt;Merel&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;Sturnus vulgaris&lt;/td&gt;
&lt;td&gt;Common starling&lt;/td&gt;
&lt;td&gt;Spreeuw&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;Passer montanus&lt;/td&gt;
&lt;td&gt;Eurasian tree sparrow&lt;/td&gt;
&lt;td&gt;Ringmus&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;Passer domesticus&lt;/td&gt;
&lt;td&gt;House sparrow&lt;/td&gt;
&lt;td&gt;Huismus&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;Emberiza citrinella&lt;/td&gt;
&lt;td&gt;Yellowhammer&lt;/td&gt;
&lt;td&gt;Geelgors&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;Prunella modularis&lt;/td&gt;
&lt;td&gt;Dunnock&lt;/td&gt;
&lt;td&gt;Heggenmus&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;Certhia brachydactyla&lt;/td&gt;
&lt;td&gt;Short-toed treecreeper&lt;/td&gt;
&lt;td&gt;Boomkruiper&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;Chloris chloris&lt;/td&gt;
&lt;td&gt;European greenfinch&lt;/td&gt;
&lt;td&gt;Groenling&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;14&lt;/td&gt;
&lt;td&gt;Sitta europaea&lt;/td&gt;
&lt;td&gt;Eurasian nuthatch&lt;/td&gt;
&lt;td&gt;Boomklever&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;Erithacus rubecula&lt;/td&gt;
&lt;td&gt;Robin&lt;/td&gt;
&lt;td&gt;Roodborstje&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;Dendrocopos major&lt;/td&gt;
&lt;td&gt;Great spotted woodpecker&lt;/td&gt;
&lt;td&gt;Grote Bonte Specht&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;Pica Pica&lt;/td&gt;
&lt;td&gt;Magpie&lt;/td&gt;
&lt;td&gt;Ekster&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;18&lt;/td&gt;
&lt;td&gt;Carduelis carduelis&lt;/td&gt;
&lt;td&gt;European goldfinch&lt;/td&gt;
&lt;td&gt;Putter&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;19&lt;/td&gt;
&lt;td&gt;Troglodytes troglodytes&lt;/td&gt;
&lt;td&gt;Eurasian wren&lt;/td&gt;
&lt;td&gt;Winterkoning&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;Turdus philomelos&lt;/td&gt;
&lt;td&gt;Song thrush&lt;/td&gt;
&lt;td&gt;Zanglijster&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;td&gt;Columba palumbus&lt;/td&gt;
&lt;td&gt;Common wood pigeon&lt;/td&gt;
&lt;td&gt;Houtduif&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;22&lt;/td&gt;
&lt;td&gt;Streptopelia decaocto&lt;/td&gt;
&lt;td&gt;Eurasian collared dove&lt;/td&gt;
&lt;td&gt;Turkse Tortel&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;23&lt;/td&gt;
&lt;td&gt;Columba Oenas&lt;/td&gt;
&lt;td&gt;Stock dove&lt;/td&gt;
&lt;td&gt;Holenduif&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;24&lt;/td&gt;
&lt;td&gt;Motacilla Alba&lt;/td&gt;
&lt;td&gt;White wagtail&lt;/td&gt;
&lt;td&gt;Witte Kwikstaart&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;td&gt;Picus Viridis&lt;/td&gt;
&lt;td&gt;European green woodpecker&lt;/td&gt;
&lt;td&gt;Groene Specht&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;26&lt;/td&gt;
&lt;td&gt;Garrulus glandarius&lt;/td&gt;
&lt;td&gt;Eurasian jay&lt;/td&gt;
&lt;td&gt;Gaai&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;27&lt;/td&gt;
&lt;td&gt;Fringilla Montifringilla&lt;/td&gt;
&lt;td&gt;Brambling&lt;/td&gt;
&lt;td&gt;Keep&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;28&lt;/td&gt;
&lt;td&gt;Turdus Iliacus&lt;/td&gt;
&lt;td&gt;Redwing&lt;/td&gt;
&lt;td&gt;Koperwiek&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;29&lt;/td&gt;
&lt;td&gt;Turdus Pilaris&lt;/td&gt;
&lt;td&gt;Fieldfare&lt;/td&gt;
&lt;td&gt;Kramsvogel&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;td&gt;Oriolus Oriolus&lt;/td&gt;
&lt;td&gt;Eurasian golden oriole&lt;/td&gt;
&lt;td&gt;Wielewaal&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;Pre-processing data&lt;/h3&gt;
&lt;p&gt;In order to re-shape the data into a format that a ML model can interpret I performed the following steps. &lt;/p&gt;
&lt;p&gt;1) I Resized the image to have a max dimension of 256 by 256
2) Centered the image and padded the sides wherever it was less than 256
3) Cut a 224 x224 section from the middle of the image&lt;/p&gt;
&lt;p&gt;This builds heavily on the python version of the opencv library as well as numpy. The result is a 224 by 224 photo from any input photo. &lt;/p&gt;
&lt;p&gt;The resizing of images might not be needed for every possible network, but it might be important to some convolutional architectures. I chose 224 by 224 because these are the dimensions that some of the pre-trained networks available in Keras - such as vgg16 [5] - work with. While it would be massively better for training time to pick a smaller size (say 32x32), the bird is generally only a small portion of the pixels in the image. I fear that if I was to limit the size too aggresively I'd limit the usefulness of my training data too much. &lt;/p&gt;
&lt;p&gt;The below code snippet shows how the resizing and centering is done.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;center_image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;Convenience function to return a centered image&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;img_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="c1"&gt;# centering&lt;/span&gt;
    &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;img_size&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
    &lt;span class="n"&gt;col&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;img_size&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
    &lt;span class="n"&gt;resized&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uint8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;resized&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;:(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;:(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;resized&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I am actually trimming the edges a little as I figured that the bird in any given photo from this data set is likely in the middle of the photo. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;#resize &lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
    &lt;span class="n"&gt;tile_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;tile_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;

&lt;span class="c1"&gt;#centering&lt;/span&gt;
&lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;center_image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;resize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tile_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;#output should be 224*224px for a quick vggnet16&lt;/span&gt;
&lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;240&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;240&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;The actual scraping&lt;/h3&gt;
&lt;p&gt;So now I have methods defined for going through the gallery, collecting the links along the way. For each link I store the metadata and look up whether the licence is in my &lt;code&gt;ALLOWED?LICENCES&lt;/code&gt; list. Roughly 60% of all photo's are blocked by a licence. If there´s a match I download the image.&lt;/p&gt;
&lt;p&gt;With the 30 bird species I defined earlier it´s just a simple list of dicts to go through for scraping. Here &lt;code&gt;bird_scraper&lt;/code&gt; takes a bird name (used for constructing a folder) and an id to query with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;species&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;bird_scraper&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;id&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="c1"&gt;# show a random photo to brighten the day&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;:&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;show_random_img_from_folder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;RAWFOLDER&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="Examples" src="/images/vogels4.png"&gt;&lt;/p&gt;
&lt;p&gt;In the end I show a random image from the samples I collected. I figured that this would be a nice screenshot to include because it demonstrates three problems:
* The bird versus background problem (when we are training, are we actually modelling the birds or are we overfitting on their habitat?)
* The odd angle 
* The bird itself might only be a very small portion of the photo&lt;/p&gt;
&lt;p&gt;Now, let's see how many photos we captured..&lt;/p&gt;
&lt;h2&gt;Act 3: Results&lt;/h2&gt;
&lt;p&gt;&lt;img alt="Scraping Results" src="/images/vogels5.png"&gt;&lt;/p&gt;
&lt;p&gt;The total number of bird photos I scraped per species is shown in the graph below. Apparently the common birds are all a bit even, while I could not query for more than 90 &lt;em&gt;Groenling&lt;/em&gt; photos. This might be a bug or some kind of anti-scraping measure, as I always thought these birds were fairly common. 
&lt;img alt="Distribution" src="/images/vogels6.png"&gt;&lt;/p&gt;
&lt;h2&gt;Discussion&lt;/h2&gt;
&lt;p&gt;After starting out I decided to limit the scraping to a max of 4000 samples per bird species, which I further brought down by &lt;em&gt;instead of scraping until I had 4000 images&lt;/em&gt; going for 4000 images and just using how many images were allowed as training data. That meant that I scraped roughly half of that number. My goal is not to build the best possible system, but only 2000 samples per bird will mean its likely difficult to train a model. &lt;/p&gt;
&lt;p&gt;While most data scientists and like will argue that scraping is perfectly legal, the legality of web scraping licenced material is much more a grey area. Roughly 60% of the data is licensed with a 'no derivative' variant or 'all rights reserved'. &lt;/p&gt;
&lt;p&gt;In total, my scraping netted in &lt;code&gt;60.149&lt;/code&gt; usable images across 30 species. While some classes have a ton of samples (also because I started off with requesting more than I needed), others have much less samples available. This skew in the data should &lt;em&gt;probably&lt;/em&gt; be addressed while constructing a model in the next post in this series.&lt;/p&gt;
&lt;p&gt;Disclaimer: this blog post details a project that's still very much underway. I intend to retrain the models before I deploy the 'final' models and further refine the technique, and then also update this blog post. The header image is one of my own photos and I will strive to include many as my own photos as test data. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This blog post benefited from ongoing discussion with experts from a variety of backgrounds.&lt;/strong&gt; I would like to thank a number of people: Linde Koeweiden, Jobien Veninga and Johan van den Burg. I would also like to thank the people behind &lt;a href="waarneming.nl"&gt;Waarneming&lt;/a&gt; for their interest in my project and pointing out issues with my approach.&lt;/p&gt;
&lt;p&gt;Papers referenced in this post:
[1]: Christin, S., Hervet, E., &amp;amp; Lecomte, N. (2019). Applications for deep learning in ecology. Methods in Ecology and Evolution, 10(10), 1632-1644.
[2]: Huang, Y. P., &amp;amp; Basanta, H. (2019). Bird image retrieval and recognition using a deep learning platform. IEEE Access, 7, 66980-66989.
[3]: Ferreira, A. C., Silva, L. R., Renna, F., Brandl, H. B., Renoult, J. P., Farine, D. R. &amp;amp; Doutrelant, C. (2019). Deep learning-based methods for individual recognition in small birds. bioRxiv, 862557.
[4]: Cats, Rats, A.I., Oh My! - Ben Hamm: https://www.youtube.com/watch?v=1A-Nf3QIJjM
[5]: Simonyan, K., &amp;amp; Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556.&lt;/p&gt;</content><category term="Projects"></category><category term="Birding"></category><category term="Programming"></category><category term="Pet Projects"></category><category term="Python"></category><category term="Web Scraping"></category><category term="Machine Learning"></category><category term="Raspberry Pi"></category></entry><entry><title>Salt on the Road - Tracking Gritters by webscraping</title><link href="www.jeffluppes.nl/salt-on-the-road-tracking-gritters-by-webscraping.html" rel="alternate"></link><published>2016-01-16T11:11:20+01:00</published><updated>2016-01-16T11:11:20+01:00</updated><author><name>Jeffrey Luppes</name></author><id>tag:None,2016-01-16:www.jeffluppes.nl/salt-on-the-road-tracking-gritters-by-webscraping.html</id><summary type="html">&lt;p&gt;&lt;img alt="Gritter - or Strooiwagen in Dutch" src="http://www.rtlnieuws.nl/sites/default/files/styles/landscape_2/public/content/images/2014/12/25/ANP-strooiwagen_0.jpg?itok=o3xMA_4s"&gt;&lt;/p&gt;
&lt;p&gt;Last year, the Dutch Rijkswaterstaat (a part of the Dutch Ministry of Infrastructure and the Environment) released a website where you could track where salt scattering trucks - also known as gritters - moved in real-time. This is particularly useful as Dutch infrastructure always seems to shut down completely during the first …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="Gritter - or Strooiwagen in Dutch" src="http://www.rtlnieuws.nl/sites/default/files/styles/landscape_2/public/content/images/2014/12/25/ANP-strooiwagen_0.jpg?itok=o3xMA_4s"&gt;&lt;/p&gt;
&lt;p&gt;Last year, the Dutch Rijkswaterstaat (a part of the Dutch Ministry of Infrastructure and the Environment) released a website where you could track where salt scattering trucks - also known as gritters - moved in real-time. This is particularly useful as Dutch infrastructure always seems to shut down completely during the first days of mild snow and you need to know if there's a chance you might make it to work today.&lt;/p&gt;
&lt;p&gt;The Rijkswaterstaat website features a Google Maps widget that shows which trucks are active and moving and which are not.&lt;/p&gt;
&lt;p&gt;&lt;img alt="The Rijkswaterstaat website" src="http://i.imgur.com/HIgVab1.png"&gt;&lt;/p&gt;
&lt;h1&gt;Getting the data&lt;/h1&gt;
&lt;p&gt;The website features an API, which while not publicly advertised can be found by opening dev tools in any modern browser and looking at the requests made by the page. This url can then be approached via the URL.&lt;/p&gt;
&lt;p&gt;Snooping around I found a nice stream of JSON data:&lt;/p&gt;
&lt;!-- more --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;108191021&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;workcode_id&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;34&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;latitude&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;52.053938&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;longitude&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;5.115533&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The response includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;coordinate pairs in latitude and longitude (in WGS84!)&lt;/li&gt;
&lt;li&gt;a truck identifier (id)&lt;/li&gt;
&lt;li&gt;a code whether the truck is active or not. (workcode_id)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Visualizing the data&lt;/h1&gt;
&lt;p&gt;I quickly wrote a small script to download this JSON from their site - every sixty seconds or so - and started to build my own real-time overview of the gritter truck by converting the data to GeoJSON and plotting it in &lt;a href="https://github.com/TNOCS/csWeb"&gt;TNO's Common Sense&lt;/a&gt;. This yielded the following image.&lt;/p&gt;
&lt;p&gt;&lt;img alt="A map of the Netherlands. Each point represents a truck. White circles indicate the truck is currently operating, while orange stands for being on standby." src="http://i.imgur.com/GlfrABw.png"&gt;&lt;/p&gt;
&lt;p&gt;At this point I could only see where they were located. If I wanted to get new data I would have to refresh my map, and I'd still be working with point data. I had to find a way to collect historical data of the trucks.&lt;/p&gt;
&lt;p&gt;A second version of the script used an array of past values to collect historical data. Every time the script requested the JSON file, I would add the new values to an array I'd connect to each truck, and save it on my local file system. With a little bit of extra code I converted these to GeoJSON &lt;a href="http://geojson.org/geojson-spec.html#linestring"&gt;LineStrings&lt;/a&gt;, which are essentially lines between each coordinate pair I received. Now I had a way to show where trucks had been moving. The following image is aggregated from a day worth of data:&lt;/p&gt;
&lt;p&gt;&lt;img alt="An overview of a day's worth of movements" src="http://i.imgur.com/h29xLYp.png"&gt;&lt;/p&gt;
&lt;p&gt;Not surprisingly, it only showed which roads were part of the Rijkswaterstaat's responsibility: main high ways et cetera. What was kind of cool though was that you could see exactly where they were, including ramps.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Highway crossing" src="http://i.imgur.com/60EEFBm.png"&gt;&lt;/p&gt;
&lt;h1&gt;Wrapping up&lt;/h1&gt;
&lt;p&gt;That's about it. I found the data, transformed it, and made a pretty image of it. Very little code had to be written thanks to the tools available.  &lt;/p&gt;
&lt;p&gt;The code can be found on &lt;a href="https://github.com/jeffluppes/strooiwagens"&gt;Github&lt;/a&gt; for anyone who wants to mess with it.&lt;/p&gt;
&lt;p&gt;*Update: The Rijkswaterstaat website has been updated and the API path has been changed. You can find the new JSON file &lt;a href="http://rijkswaterstaatstrooit.nl/wagensvol.json"&gt;here&lt;/a&gt; They also added a nice historical viewing option, which shows you where trucks have been in the past six hours. *&lt;/p&gt;</content><category term="Projects"></category><category term="Pet Project"></category><category term="Programming"></category><category term="JavaScript"></category><category term="Web Scraping"></category></entry></feed>